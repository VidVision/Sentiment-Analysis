{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The purpose of this notebook is to read both Listings & Reviews (.gz zipped) Airbnb files, then clean and merge them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs for this notebook are downloaded Airbnb files from Inside Airbnb (http://insideairbnb.com/get-the-data.html). The files of interest are listings.csv.gz and reviews.csv.gz. Note that the files are supposed to be cumulative, so a recent file should contain all previous reviews/listings. However, some listings drop off the Airbnb site, so they may only appear for a short time. Hence, we download multiple years, combine data, and then de-duplicate for a more complete dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import langdetect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set input parameters below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data'\n",
    "city = 'SanFrancisco'\n",
    "beginDate = '2018-01-01' # beginning of interested time horizon\n",
    "COVIDdate = '2020-03-11'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create listing dataframe for one city by combining files over multiple years, while de-duplicating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityList = pd.DataFrame()\n",
    "records = 0\n",
    "for f in os.listdir(directory):\n",
    "    if (f != \".DS_Store\") and (\"gz\" in f) and (city.lower() in f.lower()) and ('list' in f):\n",
    "        print(f)\n",
    "        df = pd.read_csv(os.path.join(directory, f), compression = \"gzip\")\n",
    "        print(len(df), 'records.')\n",
    "        records += len(df)\n",
    "        # select only relevant columns; note 2021 omits zipcode\n",
    "        if 'zipcode' in df.columns:\n",
    "            df = df[['id','neighbourhood_cleansed','price','zipcode','property_type','room_type','review_scores_rating']]\n",
    "        else:\n",
    "            df = df[['id','neighbourhood_cleansed','price','property_type','room_type','review_scores_rating']]\n",
    "        # rename colunns for later use & append\n",
    "        df.rename(columns = {'id':'listing_id','neighbourhood_cleansed':'neighborhood','property_type':'property','room_type':'room','review_scores_rating':'rating'}, inplace = True)\n",
    "        cityList = cityList.append(df)\n",
    "        # drop duplicate listings; earlier files contain zipcode, but 2021 file has most current price\n",
    "        cityList = cityList.drop_duplicates(subset='listing_id', keep='first')\n",
    "print('\\n')\n",
    "print(records, 'total listings processed...')\n",
    "print('de-duplicated, combined Listing dataframe for ', city,':', sep='')\n",
    "cityList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create review dataframe for one city by combining files over multiple years, while de-duplicating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cityReviews = pd.DataFrame()\n",
    "records = 0\n",
    "for f in os.listdir(directory):\n",
    "    if (f != \".DS_Store\") and (\"gz\" in f) and (city.lower() in f.lower()) and ('review' in f):\n",
    "        print(f)\n",
    "        df = pd.read_csv(os.path.join(directory, f), compression = \"gzip\")\n",
    "        print(len(df), 'records.')\n",
    "        records += len(df)\n",
    "        # select only relevant columns and convert date\n",
    "        df = df[['listing_id', 'id', 'date', 'comments']]\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        # append\n",
    "        cityReviews = cityReviews.append(df)\n",
    "        # drop duplicates & null reviews\n",
    "        cityReviews = cityReviews.drop_duplicates(subset='id')\n",
    "        cityReviews.dropna(subset=['comments'], inplace=True)\n",
    "\n",
    "print('\\n')        \n",
    "print(records, 'total reviews processed...')\n",
    "# filter based on date to obtain time horizon\n",
    "cityReviews = cityReviews[(cityReviews['date'] > beginDate)]\n",
    "timeReviews = len(cityReviews)\n",
    "print(timeReviews, 'de-duplicated reviews within time horizon of', beginDate)\n",
    "# determine percentage of Pre/Post-COVID data\n",
    "cityReviews['COVID'] = np.where(cityReviews['date'] > COVIDdate, 'Post-', 'Pre-')\n",
    "print('> COVID data breakdown:')\n",
    "COVIDper = round(100*len(cityReviews.loc[cityReviews[\"COVID\"]=='Post-'])/timeReviews, 2)\n",
    "print(COVIDper, '% of the reviews for',city,'are post-COVID.')\n",
    "cityReviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge listings & reviews into one dataframe for one city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_data = pd.merge(cityList, cityReviews, on='listing_id')\n",
    "city_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanse by filtering out non-English reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def modifieddetect(comment):\n",
    "    try:\n",
    "        return langdetect.detect(comment)\n",
    "    except:\n",
    "        return \"Error\"\n",
    "%time city_data[\"language\"] = city_data[\"comments\"].apply(modifieddetect)\n",
    "city_data = city_data.loc[city_data['language']=='en'].drop(['language','id'],axis=1)\n",
    "print('\\n')\n",
    "print('>> ',len(city_data),' reviews from ',city,', beginning ',beginDate,', are ready for analysis!', sep='')\n",
    "city_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write output file in .csv format, compressed (.gz zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = city + '.gz'\n",
    "file = city + '.csv.gz'\n",
    "city_data.to_csv(file, index=False, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
